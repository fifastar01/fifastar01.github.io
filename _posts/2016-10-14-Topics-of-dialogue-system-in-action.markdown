---
layout:     post
title:      "Topics of dialogue system in action"
subtitle:   "How to design a chatbot, part three"
date:       2016-10-14
author:     "Dennis"
header-img: "img/post-bg-2015.jpg"
tags:
    - Dialogue System
    - Chatbot
    - AI+HI
    - Multi-modal interaction
    - Conversational UI
---


Before deploying dialogue systems in practice, there are still many issues to consider.

## Challenges at hand

* Users are intolerable to certain errors  
	In task oriented context, 80-90% accurate chatbot is not enough, we need 99%+. However, current technology is not ready for fully automation. A fully automated dialogue system can hardly meet user expectation.

 * Voice/text interactions are not sufficient  
	In many scenarios, users need richer information than voice/text. For example, when user want to find the exact location of taxi, it is easier to use a dot in the map.

 * Some users are not used to natural interactions  
	Old habits die hard, many people use to click or touch to interact with computer system. It might take some time for them to shift the habit  to use text or speech.

## Artificial intelligence + human intelligence (AI+HI)
Given the gap between user expectation and current technology. It is important to put human agents in the conversation in order to make the dialogue system more accurate and reliable and form a positive feedback loop.

![][image-1]

In dialogue system, we can use group chat involving user, machine and human agent(s). Machine decides when and which human agents should be involved
based on dialogue context, user profile and human agent expertise.

In three levels of user request fulfillment, we’re trying to move from completely HI to AI+HI and finally to Completely AI.

![][image-2]


## Roles of human agents
There are mainly 3 roles of human agents:

 1. Provide more instant and richer feedback for AI  
	Human can report or correct errors in different modules of the system in speech recognition, intent identification, entity extraction, action selection. Also, human can control damage  by proactively retrieving imperfect actions made by AI and allow AI to perform “perfectly” after necessary human interventions. In this way human can provide penalty and reward feedback as intermediate steps for RL.

2. Take actions with the help of AI  
	Human can choose a final action from potential actions generated by AI or generate a final action based on suggestions made by AI.  

 3. Generate training data for AI to evolve  
	Last but not least, human can serve as data producer. Every error reporting/correction can be taken as a negative sample and every successful conversation can be taken as a positive sample. Human can also label samples that AI produces low confidence scores offline.  


## Multi-modal interaction

Multi-modal interaction enables more efficient conversations and delivers better user experience.

![][image-3]

## Combine recommender system with dialogue system
AI can anticipate user’s request and invoke proactive recommendations when no user input is required.  Such context-based recommendations have 30-50% conversion rates. Context-based recommendation might be the unified model for CUI.

![][image-4]

[image-1]:	{{ site.baseurl}}/img/deploy/loop.png
[image-2]:	{{ site.baseurl}}/img/deploy/AIHI.png
[image-3]:	{{ site.baseurl}}/img/deploy/Multi.png
[image-4]:	{{ site.baseurl}}/img/deploy/Rec.png